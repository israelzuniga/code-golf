{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types will be printed.\n"
     ]
    }
   ],
   "source": [
    "%showTypes on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.SparkContext = org.apache.spark.SparkContext@13a87f6f\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.3\n",
      "local[*]\n",
      "Running locally? true\n"
     ]
    }
   ],
   "source": [
    "println(sc.version)\n",
    "println(sc.master)\n",
    "println(\"Running locally? \" + sc.isLocal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "info: (message: String)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def info(message: String): String = {\n",
    "    println(message)\n",
    "    \n",
    "    message\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error: (message: String)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def error(message: String): String = {\n",
    "    val fullMessage = s\"\"\"\n",
    "        |***********\n",
    "        |\n",
    "        | ERROR: $message\n",
    "        |\n",
    "        |***********\n",
    "        \"\"\".stripMargin\n",
    "    println(fullMessage)\n",
    "    \n",
    "    fullMessage\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is well.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "infoString: String = All is well.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "infoString: String = All is well.\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val infoString = info(\"All is well.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********\n",
      "\n",
      " ERROR: Uh oh...\n",
      "\n",
      "***********\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "errorString: String = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "***********\n",
       " ERROR: Uh oh...\n",
       "***********\n",
       "        \"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "errorString: String = \n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val errorString = error(\"Uh oh...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\n",
       "***********\n",
       " ERROR: Uh oh...\n",
       "***********\n",
       "        \"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "String = \n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Use braces for expressions: 2.4.3.\n",
       "You can omit the braces when just using a variable: org.apache.spark.SparkContext@32c3891d\n",
       "However, watch for ambiguities like org.apache.spark.SparkContext@32c3891dandextrastuff\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "String = \n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s\"\"\"Use braces for expressions: ${sc.version}.\n",
    "You can omit the braces when just using a variable: $sc\n",
    "However, watch for ambiguities like ${sc}andextrastuff\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\n",
       "line 1\n",
       "  line 2\n",
       " line 3\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "String = \n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s\"\"\"\n",
    "    |line 1\n",
    "    |  line 2\n",
    "    |  | line 3\n",
    "    |\"\"\".stripMargin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\n",
       "line 1\n",
       "  line 2\n",
       "  line 3\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "String = \n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s\"\"\"\n",
    "    |line 1\n",
    "    |  line 2\n",
    "    |  |  line 3\n",
    "    |\"\"\".stripMargin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Char = /\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "String = /\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shakespeare = /home/jovyan/work/data-jesfs/shakespeare\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/home/jovyan/work/data-jesfs/shakespeare"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val shakespeare = new File(\"/home/jovyan/work/data-jesfs/shakespeare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/data-jesfs/shakespeare exists\n",
      "success = true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "success: Boolean = true\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "success: Boolean = true\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val success = if (shakespeare.exists == false) {\n",
    "    error(s\"Data directory path doesn't exist! $shakespeare\")\n",
    "    false\n",
    "} else {\n",
    "    info(s\"$shakespeare exists\")\n",
    "    true\n",
    "}\n",
    "println(\"success = \" + success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking that the plays are in /home/jovyan/work/data-jesfs/shakespeare:\n",
      "Finished!\n",
      "All plays found!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pathSeparator: String = /\n",
       "targetDirName: String = /home/jovyan/work/data-jesfs/shakespeare\n",
       "plays: Seq[String] = List(tamingoftheshrew, comedyoferrors, loveslabourslost, midsummersnightsdream, merrywivesofwindsor, muchadoaboutnothing, asyoulikeit, twelfthnight)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Any = All plays found!\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pathSeparator = File.separator\n",
    "val targetDirName = shakespeare.toString\n",
    "val plays = Seq(\n",
    "    \"tamingoftheshrew\", \"comedyoferrors\", \"loveslabourslost\", \"midsummersnightsdream\",\n",
    "    \"merrywivesofwindsor\", \"muchadoaboutnothing\", \"asyoulikeit\", \"twelfthnight\")\n",
    "\n",
    "if (success) {\n",
    "    println(s\"Checking that the plays are in $shakespeare:\")\n",
    "    val failures = for {\n",
    "        play <- plays\n",
    "        playFileName = targetDirName + pathSeparator + play\n",
    "        playFile = new File(playFileName)\n",
    "        if (playFile.exists == false)\n",
    "    } yield {\n",
    "        s\"$playFileName:\\tNOT FOUND!!\"\n",
    "    }\n",
    "    \n",
    "    println(\"Finished!\")\n",
    "    if (failures.size == 0) {\n",
    "        info(\"All plays found!\")\n",
    "    } else {\n",
    "        println(\"The following expected plays were not found:\")\n",
    "        failures.foreach(play => error(play))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass prinln as the function to use for each element:\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n"
     ]
    }
   ],
   "source": [
    "println(\"Pass prinln as the function to use for each element:\")\n",
    "\n",
    "plays.foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymous function   println `str => println(str)`\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n"
     ]
    }
   ],
   "source": [
    "println(\"Anonymous function   println `str => println(str)`\")\n",
    "plays.foreach(str => println(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why do we need to name this argument? Scala lets us use _ as a placeholder.\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n"
     ]
    }
   ],
   "source": [
    "println(\"\\nWhy do we need to name this argument? Scala lets us use _ as a placeholder.\")\n",
    "plays.foreach(println(_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For longer functions, you can use {...} instead of (...).\n",
      "Why? Because it gives you the familiar multiline block syntax with {...}\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n"
     ]
    }
   ],
   "source": [
    "println(\"\\nFor longer functions, you can use {...} instead of (...).\")\n",
    "println(\"Why? Because it gives you the familiar multiline block syntax with {...}\")\n",
    "plays.foreach {\n",
    "  (str: String) => println(str)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The _ placeholder can be used *once* for each argument in the list.\n",
      "As an assume, use `reduceLeft` to sum some integers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "integers: scala.collection.immutable.Range.Inclusive = Range(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Int = 55\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "println(\"\\nThe _ placeholder can be used *once* for each argument in the list.\")\n",
    "println(\"As an assume, use `reduceLeft` to sum some integers.\")\n",
    "\n",
    "val integers = 0 to 10\n",
    "integers.reduceLeft((i,j) => i+j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int = 55\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integers.reduceLeft(_+_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iiFirstPass1: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[9] at mapValues at <console>:44\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "iiFirstPass1: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[9] at mapValues at <console>:44\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val iiFirstPass1 = sc.wholeTextFiles(shakespeare.toString)\n",
    "                    .flatMap { location_contents_tuple2 =>\n",
    "                        val words = location_contents_tuple2._2.split(\"\"\"\\W+\"\"\")\n",
    "                        val fileName = location_contents_tuple2._1.split(pathSeparator).last\n",
    "                        words.map(word => ((word, fileName), 1))\n",
    "                        }\n",
    "                    .\n",
    "                    .reduceByKey((count1, count2) => count1 + count2)\n",
    "                    .map { word_file_count_tup3 =>\n",
    "                        (word_file_count_tup3._1._1, (word_file_count_tup3._1._2, word_file_count_tup3._2))\n",
    "                        }\n",
    "                    .groupByKey\n",
    "                    .sortByKey(ascending = true)\n",
    "                    .mapValues { iterable =>\n",
    "                        val vect = iterable.toVector.sortBy { file_count_tup2 =>\n",
    "                            (-file_count_tup2._2, file_count_tup2._1)\n",
    "                        }\n",
    "                        vect.mkString(\",\")\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array[(String, String)] = Array((\"\",(asyoulikeit,1),(comedyoferrors,1),(loveslabourslost,1),(merrywivesofwindsor,1),(midsummersnightsdream,1),(muchadoaboutnothing,1),(tamingoftheshrew,1),(twelfthnight,1)), (A,(loveslabourslost,78),(tamingoftheshrew,59),(twelfthnight,47),(comedyoferrors,42),(midsummersnightsdream,39),(merrywivesofwindsor,38),(asyoulikeit,34),(muchadoaboutnothing,31)), (ABOUT,(muchadoaboutnothing,18)))\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iiFirstPass1.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "steb by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fileContents: org.apache.spark.rdd.RDD[(String, String)] = /home/jovyan/work/data-jesfs/shakespeare MapPartitionsRDD[3] at wholeTextFiles at <console>:30\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fileContents: org.apache.spark.rdd.RDD[(String, String)] = /home/jovyan/work/data-jesfs/shakespeare MapPartitionsRDD[3] at wholeTextFiles at <console>:30\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fileContents = sc.wholeTextFiles(shakespeare.toString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.rdd.RDD[(String, String)] = /home/jovyan/work/data-jesfs/shakespeare MapPartitionsRDD[1] at wholeTextFiles at <console>:30\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(String, Int, Double, (String, Long)) = (foo,101,3.14159,(bar,202))\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\"foo\", 101, 3.14159, (\"bar\", 202L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int, Int, Int, (Int, Int, Int), (Int, Int, Int, (Int, Int, Int))) = (1,2,3,(1,2,3),(1,2,3,(4,5,6)))\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,2,3,(1,2,3), (1,2,3,(4,5,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 8\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileContents.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int = 3\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Seq(1,2,3).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wordFileNameOnes: org.apache.spark.rdd.RDD[((String, String), Int)] = MapPartitionsRDD[17] at flatMap at <console>:32\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "wordFileNameOnes: org.apache.spark.rdd.RDD[((String, String), Int)] = MapPartitionsRDD[17] at flatMap at <console>:32\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val wordFileNameOnes = fileContents.flatMap { location_contents_tuple2 => \n",
    "    val words = location_contents_tuple2._2.split(\"\"\"\\W+\"\"\")\n",
    "        .filter(word => word.size > 0)\n",
    "    val fileName = location_contents_tuple2._1.split(pathSeparator).last\n",
    "    words.map(word => ((word.toLowerCase, fileName), 1))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 173328\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordFileNameOnes.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((the,merrywivesofwindsor),1)\n",
      "((merry,merrywivesofwindsor),1)\n",
      "((wives,merrywivesofwindsor),1)\n",
      "((of,merrywivesofwindsor),1)\n",
      "((windsor,merrywivesofwindsor),1)\n",
      "((dramatis,merrywivesofwindsor),1)\n",
      "((personae,merrywivesofwindsor),1)\n",
      "((sir,merrywivesofwindsor),1)\n",
      "((john,merrywivesofwindsor),1)\n",
      "((falstaff,merrywivesofwindsor),1)\n"
     ]
    }
   ],
   "source": [
    "wordFileNameOnes.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordFileNameOnes.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniques: org.apache.spark.rdd.RDD[((String, String), Int)] = ShuffledRDD[5] at reduceByKey at <console>:28\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "uniques: org.apache.spark.rdd.RDD[((String, String), Int)] = ShuffledRDD[5] at reduceByKey at <console>:28\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val uniques = wordFileNameOnes.reduceByKey((count1, count2) => count1 + count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 27276\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((dexterity,merrywivesofwindsor),1)\n",
      "((force,muchadoaboutnothing),2)\n",
      "((whole,comedyoferrors),2)\n",
      "((lamb,muchadoaboutnothing),2)\n",
      "((blunt,tamingoftheshrew),3)\n",
      "((letter,merrywivesofwindsor),19)\n",
      "((crest,asyoulikeit),1)\n",
      "((bestow,asyoulikeit),1)\n",
      "((rear,midsummersnightsdream),1)\n",
      "((crossing,tamingoftheshrew),1)\n",
      "((wronged,merrywivesofwindsor),4)\n",
      "((S,tamingoftheshrew),10)\n",
      "((HIPPOLYTA,midsummersnightsdream),19)\n",
      "((revolve,twelfthnight),1)\n",
      "((er,merrywivesofwindsor),11)\n",
      "((renown,asyoulikeit),1)\n",
      "((cubiculo,twelfthnight),1)\n",
      "((All,twelfthnight),3)\n",
      "((power,loveslabourslost),8)\n",
      "((Albeit,asyoulikeit),1)\n",
      "((lips,tamingoftheshrew),3)\n",
      "((upshot,twelfthnight),1)\n",
      "((approach,midsummersnightsdream),4)\n",
      "((mean,muchadoaboutnothing),5)\n",
      "((embossed,asyoulikeit),1)\n",
      "((varnish,loveslabourslost),2)\n",
      "((Apollo,midsummersnightsdream),1)\n",
      "((spangled,midsummersnightsdream),1)\n",
      "((gentlemen,comedyoferrors),1)\n",
      "((Rebuke,loveslabourslost),1)\n"
     ]
    }
   ],
   "source": [
    "uniques.take(30).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words: org.apache.spark.rdd.RDD[(String, (String, Int))] = MapPartitionsRDD[6] at map at <console>:28\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "words: org.apache.spark.rdd.RDD[(String, (String, Int))] = MapPartitionsRDD[6] at map at <console>:28\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val words = uniques.map {\n",
    "    word_file_count_tup3 => \n",
    "        (word_file_count_tup3._1._1, (word_file_count_tup3._1._2, word_file_count_tup3._2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wordGroups: org.apache.spark.rdd.RDD[(String, Iterable[(String, Int)])] = ShuffledRDD[14] at sortByKey at <console>:28\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "wordGroups: org.apache.spark.rdd.RDD[(String, Iterable[(String, Int)])] = ShuffledRDD[14] at sortByKey at <console>:28\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val wordGroups = words.groupByKey.sortByKey(ascending = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Long = 11951\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordGroups.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(,CompactBuffer((tamingoftheshrew,1), (asyoulikeit,1), (merrywivesofwindsor,1), (comedyoferrors,1), (midsummersnightsdream,1), (twelfthnight,1), (loveslabourslost,1), (muchadoaboutnothing,1)))\n",
      "(A,CompactBuffer((loveslabourslost,78), (midsummersnightsdream,39), (muchadoaboutnothing,31), (merrywivesofwindsor,38), (comedyoferrors,42), (asyoulikeit,34), (twelfthnight,47), (tamingoftheshrew,59)))\n",
      "(ABOUT,CompactBuffer((muchadoaboutnothing,18)))\n",
      "(ACT,CompactBuffer((asyoulikeit,22), (comedyoferrors,11), (tamingoftheshrew,12), (loveslabourslost,9), (muchadoaboutnothing,17), (twelfthnight,18), (merrywivesofwindsor,23), (midsummersnightsdream,9)))\n",
      "(ADAM,CompactBuffer((asyoulikeit,16)))\n",
      "(ADO,CompactBuffer((muchadoaboutnothing,18)))\n",
      "(ADRIANA,CompactBuffer((comedyoferrors,85)))\n",
      "(ADRIANO,CompactBuffer((loveslabourslost,111)))\n",
      "(AEGEON,CompactBuffer((comedyoferrors,20)))\n",
      "(AEMELIA,CompactBuffer((comedyoferrors,16)))\n",
      "(AEMILIA,CompactBuffer((comedyoferrors,3)))\n",
      "(AEacides,CompactBuffer((tamingoftheshrew,1)))\n",
      "(AEgeon,CompactBuffer((comedyoferrors,7)))\n",
      "(AEgle,CompactBuffer((midsummersnightsdream,1)))\n",
      "(AEmilia,CompactBuffer((comedyoferrors,4)))\n",
      "(AEsculapius,CompactBuffer((merrywivesofwindsor,1)))\n",
      "(AGUECHEEK,CompactBuffer((twelfthnight,2)))\n",
      "(ALL,CompactBuffer((midsummersnightsdream,2), (tamingoftheshrew,2)))\n",
      "(AMIENS,CompactBuffer((asyoulikeit,16)))\n",
      "(ANDREW,CompactBuffer((twelfthnight,104)))\n",
      "(ANGELO,CompactBuffer((comedyoferrors,36)))\n",
      "(ANN,CompactBuffer((merrywivesofwindsor,1)))\n",
      "(ANNE,CompactBuffer((merrywivesofwindsor,27)))\n",
      "(ANTIPHOLUS,CompactBuffer((comedyoferrors,195)))\n",
      "(ANTONIO,CompactBuffer((muchadoaboutnothing,32), (twelfthnight,32)))\n",
      "(ARMADO,CompactBuffer((loveslabourslost,111)))\n",
      "(AS,CompactBuffer((asyoulikeit,24)))\n",
      "(AUDREY,CompactBuffer((asyoulikeit,18)))\n",
      "(Abate,CompactBuffer((midsummersnightsdream,1), (loveslabourslost,1)))\n",
      "(Abbess,CompactBuffer((comedyoferrors,2)))\n"
     ]
    }
   ],
   "source": [
    "wordGroups.take(30).foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iiFirstPass2: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[15] at mapValues at <console>:28\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "iiFirstPass2: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[15] at mapValues at <console>:28\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val iiFirstPass2 = wordGroups.mapValues {\n",
    "    iterable => val vect = iterable.toVector.sortBy {\n",
    "        file_count_tup2 => (-file_count_tup2._2, file_count_tup2._1)\n",
    "    }\n",
    "    vect.mkString(\",\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(,(asyoulikeit,1),(comedyoferrors,1),(loveslabourslost,1),(merrywivesofwindsor,1),(midsummersnightsdream,1),(muchadoaboutnothing,1),(tamingoftheshrew,1),(twelfthnight,1))\n",
      "(A,(loveslabourslost,78),(tamingoftheshrew,59),(twelfthnight,47),(comedyoferrors,42),(midsummersnightsdream,39),(merrywivesofwindsor,38),(asyoulikeit,34),(muchadoaboutnothing,31))\n",
      "(ABOUT,(muchadoaboutnothing,18))\n",
      "(ACT,(merrywivesofwindsor,23),(asyoulikeit,22),(twelfthnight,18),(muchadoaboutnothing,17),(tamingoftheshrew,12),(comedyoferrors,11),(loveslabourslost,9),(midsummersnightsdream,9))\n",
      "(ADAM,(asyoulikeit,16))\n",
      "(ADO,(muchadoaboutnothing,18))\n",
      "(ADRIANA,(comedyoferrors,85))\n",
      "(ADRIANO,(loveslabourslost,111))\n",
      "(AEGEON,(comedyoferrors,20))\n",
      "(AEMELIA,(comedyoferrors,16))\n",
      "(AEMILIA,(comedyoferrors,3))\n",
      "(AEacides,(tamingoftheshrew,1))\n",
      "(AEgeon,(comedyoferrors,7))\n",
      "(AEgle,(midsummersnightsdream,1))\n",
      "(AEmilia,(comedyoferrors,4))\n",
      "(AEsculapius,(merrywivesofwindsor,1))\n",
      "(AGUECHEEK,(twelfthnight,2))\n",
      "(ALL,(midsummersnightsdream,2),(tamingoftheshrew,2))\n",
      "(AMIENS,(asyoulikeit,16))\n",
      "(ANDREW,(twelfthnight,104))\n",
      "(ANGELO,(comedyoferrors,36))\n",
      "(ANN,(merrywivesofwindsor,1))\n",
      "(ANNE,(merrywivesofwindsor,27))\n",
      "(ANTIPHOLUS,(comedyoferrors,195))\n",
      "(ANTONIO,(muchadoaboutnothing,32),(twelfthnight,32))\n",
      "(ARMADO,(loveslabourslost,111))\n",
      "(AS,(asyoulikeit,24))\n",
      "(AUDREY,(asyoulikeit,18))\n",
      "(Abate,(loveslabourslost,1),(midsummersnightsdream,1))\n",
      "(Abbess,(comedyoferrors,2))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iiFirstPass2.take(30).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Pattern Matching\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ii1: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[27] at mapValues at <console>:48\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ii1: org.apache.spark.rdd.RDD[(String, String)] = MapPartitionsRDD[27] at mapValues at <console>:48\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ii1 = sc.wholeTextFiles(shakespeare.toString).\n",
    "    flatMap {\n",
    "        case (location, contents) => \n",
    "            val words = contents.split(\"\"\"\\W+\"\"\").\n",
    "                filter(word => word.size > 0)                      // #1\n",
    "            val fileName = location.split(pathSeparator).last\n",
    "            words.map(word => ((word.toLowerCase, fileName), 1))   // #2\n",
    "    }.\n",
    "    reduceByKey((count1, count2) => count1 + count2).\n",
    "    map { \n",
    "        case ((word, fileName), count) => (word, (fileName, count)) \n",
    "    }.\n",
    "    groupByKey.\n",
    "    sortByKey(ascending = true).\n",
    "    mapValues { iterable => \n",
    "        val vect = iterable.toVector.sortBy { \n",
    "            case (fileName, count) => (-count, fileName) \n",
    "        }\n",
    "        vect.mkString(\",\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@bbf1695\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one deprecation warning; re-run with -deprecation for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@bbf1695\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SQLContext\n",
    "val sqlContext = new SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ii1DF: org.apache.spark.sql.DataFrame = [word: string, locations_counts: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ii1DF: org.apache.spark.sql.DataFrame = [word: string, locations_counts: string]\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ii1DF = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
